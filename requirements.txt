torch>=2.4.0
triton>=3.0.0
transformers>=4.51.0
xxhash
psutil
# flash-attn # Need to install torch in advance. Use `pip install flash-attn --no-build-isolation` to install
